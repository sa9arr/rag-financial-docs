{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b335514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bfee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lightrag-hku\n",
      "Version: 1.4.6\n",
      "Summary: LightRAG: Simple and Fast Retrieval-Augmented Generation\n",
      "Home-page: https://github.com/HKUDS/LightRAG\n",
      "Author: Zirui Guo\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/ozymas/miniconda3/envs/finrag/lib/python3.12/site-packages\n",
      "Requires: aiohttp, configparser, dotenv, future, json-repair, nano-vectordb, networkx, numpy, pandas, pipmaster, pydantic, python-dotenv, pyuca, setuptools, tenacity, tiktoken, xlsxwriter\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show lightrag-hku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb9d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag import LightRAG, QueryParam\n",
    "import asyncio\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed, gpt_4o_complete\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4520b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def initialize_rag():\n",
    "    rag = LightRAG(\n",
    "        working_dir= \"../aapl_financial_data\",\n",
    "        embedding_func = openai_embed,\n",
    "        llm_model_func = gpt_4o_mini_complete,\n",
    "        enable_llm_cache= False\n",
    "\n",
    "    )\n",
    "    await rag.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957fbc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../aapl_financial_data/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../aapl_financial_data/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '../aapl_financial_data/vdb_chunks.json'} 0 data\n",
      "Rerank is enabled but no rerank_model_func provided. Reranking will be skipped.\n"
     ]
    }
   ],
   "source": [
    "rag = await initialize_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e75b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./markdown_file.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     await rag.ainsert(f.read())\n",
    "\n",
    "\n",
    "#commented out to avoid re-ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e877a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../aapl_financial_data/2022 Q3 AAPL.md\") as f:\n",
    "    markdown_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc19b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [markdown_text]\n",
    "file_paths = [\"aapl_financial_data/2022 Q3 AAPL.md\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3230f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'insert_20250810_181435_d9566a84'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rag.ainsert(documents, file_paths= file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ba5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    " \n",
    "    rag = await (initialize_rag())\n",
    "    query_param = QueryParam(\n",
    "        mode = \"mix\", only_need_context=False,  \n",
    "    )\n",
    "    \n",
    "    response = rag.query(\n",
    "    \"\"\" \n",
    "    \"What is the document about?\n",
    "\n",
    "        \n",
    "\"\"\",\n",
    "    param=query_param,\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    )\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a744326",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
